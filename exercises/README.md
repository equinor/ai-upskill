# Exercises

- **Employee feedback summarization** &mdash; see [feedback.md](./feedback.md) &mdash; especially for groups of line managers or human reousrces people
- **Meeting transcript summarization** &mdash; see [transcript.md](./transcript.md) &mdash; for groups of administrators or technical people
- **Helpdesk ticket analysis** &mdash; see [helpdesk.md](./helpdesk.md) &mdash; for groups of technical people and support staff

In each case, the following can be discussed (but the emphasis will naturally change depending on the group and the exercise):

- 'State of the art': how well, and how safely, do we currently do this task?
- Model accuracy: how can we measure, ideally quantitatively, the model's performance?
- Impact of prompt engineering: how much variance is there when the prompt is changed?
- Standardizing prompts: would it help to use a fixed, prescribed prompt for the task?
- Testing output, validation: how could we check the model's responses in real time?
- Sensitive data: how will we deal with personal or confidential information?
- Transparency: how should we tell users and subjects about the role of AI in the task?


## License

All content is &copy; Equinor / Matt Hall, and licensed [CC BY](https://creativecommons.org/licenses/by/4.0/), please re-use and re-mix.
