# Safety moment

_Matt Hall, TDI EDT DSD, `mtha@equinor.com`_

Think back to the last time you flew in a plane. Maybe it was earlier this morning.

How many affordances to safety can you see from your seat?

There are quite a few: smoke detectors, emergency alarms and lighting, escape route marking, the safety briefing, notices everywhere, flame retardent materials, even your seat can withstand 16G (about double what you can stand!). Of course, there is national and international legislation, construction codes, inspections, and all sorts of infrastructure keeping us safe.

Aviation is perfectly dangerous, yet it's the safest way to travel today... but of course it was not always like that.

The first flight was in 1903. The US did not seriously regulate the activity until the Air Commerce Act in 1926, and they only did that because the industry asked them to. The international community was a bit more organized and met in 1910 to start establishing a code of law. The Great War slowed things down a bit, but the International Civil Aviation Organization was established in 1922, nearly 20 years after the first flight, and at a time when you could probably fit everyone who had ever flown into a large room. 

ICAO alone publishes a lot of safety regulation, like the 65-page [Document 10049, Manual on the Approval and Use of Child Restraint Systems](https://d3n8a8pro7vhmx.cloudfront.net/afacwa/pages/2302/attachments/original/1532020664/10049_Manual_on_use_of_CRS_english_final.pdf?1532020664). They update and publish thousands of such manuals multiple times each year.

The arrival of generative AI, especially the release (or detonation?) of ChatGPT at the end of November 2022, was perhaps analogous to that first flight. A new but potentially dangerous technology. But ChatGPT reached 100 million users in less than 2 months. Flight took decades to reach that number of users, and even the World-Wide Web took 7 years. But per today, generative AI is essentially unregulated and &mdash; worse &mdash; society has almost no intuition for when or how or why it can be harmful.

Let's look at `chat.equinor.com`. Has anyone **never** used this tool? Feel free to follow along.

_At this point, you can check out the app, explain the **Information** page to people (plain ChatGPT, no Equinor information, infosec rules, etc), and give some examples. Or you can play [The Hallucination Game](./hallucination-game.md)._


## Resources

- [Equinor's Responsible AI team](https://statoilsrm.sharepoint.com/sites/ResponsibleAI2) is based in Trondheim. Get in touch with them!
- If you're interested in learning more about the risks associated with LLMs and generative AI, [this video from Phaedra Boinodiris at IBM](https://www.youtube.com/watch?v=r4kButlDLUc) is informative and technical but totally approachable. IBM's other videos are also great.
- If you're looking for more education content or need training for your team, get in touch with [AI Upskill](https://statoilsrm.sharepoint.com/sites/DigitalAcademy2/SitePages/AI-Upskill.aspx).
