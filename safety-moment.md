# Safety moment

Think back to the last time you flew in a plane. Maybe it was earlier this morning.

How many affordances to safety can you see from your seat?

There are quite a few: smoke detectors, emergency alarms and lighting, escape route marking, the safety briefing, notices everywhere, flame retardent materials, even your seat can withstand 16G (about double what you can stand!). Of course, there is national and international legislation, construction codes, inspections, and all sorts of infrastructure keeping us safe.

Aviation is perfectly dangerous, yet it's the safest way to travel today... but of course it was not always like that.

The first flight was in 1903. The US did not seriously regulate the activity until the Air Commerce Act in 1926, and they only did that because the industry asked them to. The international community was a bit more organized and met in 1910 to start establishing a code of law. The Great War slowed things down a bit, but the International Civil Aviation Organization was established in 1922, nearly 20 years after the first flight, and at a time when you could probably fit everyone who had ever flown into a large room. 

ICAO alone publishes a lot of safety regulation, like the 65-page [Document 10049, Manual on the Approval and Use of Child Restraint Systems](https://d3n8a8pro7vhmx.cloudfront.net/afacwa/pages/2302/attachments/original/1532020664/10049_Manual_on_use_of_CRS_english_final.pdf?1532020664). They update and publish thousands of such manuals multiple times each year.

The arrival of generative AI, especially the release (or detonation?) of ChatGPT at the end of November 2022, was perhaps analogous to that first flight. A new but potentially dangerous technology. But ChatGPT reached 100 million users in less than 2 months. Flight took decades to reach that number of users, and even the World-Wide Web took 7 years. But per today, generative AI is completely unregulated and &mdash; worse &mdash; society has almost no intuition for when or how or why it can be harmful.

Let's look at `chat.equinor.com`. Has anyone **never** used this tool? Feel free to follow along.

Let's ask a question: "Tell me about Equinor." The answer is quite reasonable. There is no doubt that this technology is remarkable.

I have a follow-up question, "Why did Statoil get out of the whale oil business in 1987?". The model will almost always reply with a completely made up story (Statoil was never in the whale oil business). The justification can be quite elaborate. As usual, it is eloquent and very believable.

Language models rarely push back or ask for clarification. They are eager-to-please and borderline sycophantic. 
